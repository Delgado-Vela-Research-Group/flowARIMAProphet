# -*- coding: utf-8 -*-
"""quantileregression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15QW8uKxPO8XXGZcR82Pztu5kh849rnDT
"""

import nbconvert
import os            ##  This module is for "operating system" interfaces
import sys           ##  This module is for functionality relevant to the python run time
import numpy as np
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
GOOGLE_DRIVE_PATH = os.path.join('drive','My Drive', '/content/drive/MyDrive/Colab Notebooks/PhD research/')

sys.path.append(GOOGLE_DRIVE_PATH)
os.chdir(GOOGLE_DRIVE_PATH)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import genpareto
from sklearn.linear_model import QuantileRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import permutation_importance
import seaborn as sns
import holidays

data = pd.read_csv('plant_flow_data.csv')
data['date'] = pd.to_datetime(data['date'])
data.set_index('date', inplace=True)

# extract some features as model inputs. Need to show later that these may impact flow to plant. some visuals are needed in the write up or SI
data['year'] = data.index.year
data['month'] = data.index.month
data['day'] = data.index.day
data['day_of_week'] = data.index.dayofweek
data['is_weekend'] = (data['day_of_week'] >= 5).astype(int) #operator mentioned that flow over the weekend increases substantially. remember to show this in a plot
data['flow_rolling_mean_7'] = data['flow'].rolling(window=7).mean()  #provide the source of why the 7day average flow is important. Need to check my literature and update this accordingly
data['flow_rolling_std_7'] = data['flow'].rolling(window=7).std()
data['flow_lag_1'] = data['flow'].shift(1)
data['WOY'] = data.index.isocalendar().week


us_holidays = holidays.US(years=data.index.year.unique())
data['holiday'] = data.index.to_series().apply(lambda x: 1 if x in us_holidays else 0) #there is some literature supporting that holidays impact flow changes. add these papers here.

for n in range(2, 11):
    data[f'rainfall_rolling_avg_{n}'] = data['rainfall'].rolling(window=n).mean() #this was added based on findings from this paper:https://pubs.acs.org/doi/epdf/10.1021/acsestwater.3c00155?ref=article_openPDF
data.dropna(inplace=True)

target = data['flow']
features = data.drop(columns=['flow'])
if 'season' in features.columns:
    features = pd.get_dummies(features, columns=['season'], drop_first=True)

scaler = StandardScaler()  #we do some scaling here. there is supporting literature that scaling improves model performance. Please provide this in the discussion
features_scaled = scaler.fit_transform(features)
features_scaled_df = pd.DataFrame(features_scaled, columns=features.columns)


threshold = np.percentile(target, 95) #can we find this extreme value automatically???
params = genpareto.fit(target[target > threshold]) #understand tail behavior here - critical for high flow events
shape, loc, scale = params

# baseline - start with equal weights ensures that all observations are treated fairly before any adjustments. then focus on exceedances over threshold to isolate these outliers. based on GPD to assign weights that reflect the probability of these extreme events occurring
# for consistency we also normalize weights to a comparable scale. the penalty to the weights of extreme values help us emphasize importance - need to have model that is sensitive to these values. the idea is that robustness in predicting extreme events is improved...

def calculate_adaptive_weights(data, shape, loc, scale, threshold, extreme_penalty=1.0):
    weights = np.ones(len(data))
    exceedances = data > threshold
    weights[exceedances] = genpareto.pdf(data[exceedances], shape, loc=loc, scale=scale)
    weights = weights / np.max(weights)


    extreme_threshold = np.percentile(data, 90)  #penalty term to 90th percentile or higher
    weights[data >= extreme_threshold] *= extreme_penalty
    return weights

#this is a scoring function to minimize error and maximize R²
def custom_scoring(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return -mae + r2


tscv = TimeSeriesSplit(n_splits=5) #cross-validation and quantile regression with GridSearch to minimize model overfitting
quantiles = [0.5, 0.75, 0.9]
best_results = {}

for tau in quantiles:
    quantile_regressor = QuantileRegressor(quantile=tau, alpha=1e-3)

    penalty_grid = {'extreme_penalty': np.linspace(0.5, 5.0, 10)}
    best_score = -np.inf
    best_penalty = 1.0

    for extreme_penalty in penalty_grid['extreme_penalty']:
        fold_scores = []

        for train_index, test_index in tscv.split(features):
            X_train, X_test = features_scaled[train_index], features_scaled[test_index]
            y_train, y_test = target.iloc[train_index], target.iloc[test_index]
            weights_train = calculate_adaptive_weights(y_train.values, shape, loc, scale, threshold, extreme_penalty)


            quantile_regressor.fit(X_train, y_train, sample_weight=weights_train) # here we are fitting and predicting for the current fold
            y_pred = quantile_regressor.predict(X_test)
            score = custom_scoring(y_test, y_pred)
            fold_scores.append(score)
        avg_score = np.mean(fold_scores)
        if avg_score > best_score:
            best_score = avg_score
            best_penalty = extreme_penalty
    best_results[tau] = {'penalty': best_penalty, 'score': best_score}
    print(f'Best penalty for quantile {tau}: {best_penalty} with score {best_score:.2f}') # here we are capturing the best penalty for each quantile

performance_metrics = {}
for tau in quantiles:
    best_penalty = best_results[tau]['penalty']
    weights = calculate_adaptive_weights(target.values, shape, loc, scale, threshold, best_penalty)


    quantile_regressor = QuantileRegressor(quantile=tau, alpha=1e-8)
    quantile_regressor.fit(features, target, sample_weight=weights)
    y_pred = quantile_regressor.predict(features)
    mae = mean_absolute_error(target, y_pred)
    r2 = r2_score(target, y_pred)

    performance_metrics[tau] = {'MAE': mae, 'R²': r2}
    print(f'Quantile: {tau}, MAE: {mae:.2f}, R²: {r2:.2f}')

###########visualizations come here################################
performance_df = pd.DataFrame(performance_metrics).T
performance_df.plot(kind='bar', figsize=(10, 5))
plt.title('model performance for the different quantiles')
plt.ylabel('score')
plt.xticks(rotation=0)
plt.grid(axis='y',visible=False)
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(target.index, target, label='actual flow', color='blue', alpha=0.5)

for tau in quantiles:
    best_penalty = best_results[tau]['penalty']
    weights = calculate_adaptive_weights(target.values, shape, loc, scale, threshold, best_penalty)

    quantile_regressor = QuantileRegressor(quantile=tau, alpha=1e-3)
    quantile_regressor.fit(features, target, sample_weight=weights)
    y_pred = quantile_regressor.predict(features)

    plt.plot(target.index, y_pred, label=f'Quantile {tau} (Penalty={best_penalty})', linestyle='--')

plt.title('flow predictions with optimized penalty quantile regression')
plt.xlabel('date')
plt.ylabel('flow (million gallons per day)')
plt.grid(False)
plt.legend()
plt.show()

results = permutation_importance(quantile_regressor, features_scaled_df, target, n_repeats=30, random_state=0)

importance_df = pd.DataFrame({
    'Feature': features.columns,
    'Importance': results.importances_mean
})

# lets get our top four features
top_four_features = importance_df.sort_values(by='Importance', ascending=False).head(4)
plt.figure(figsize=(8, 4))
sns.barplot(x='Importance', y='Feature', data=top_four_features, palette='viridis')
plt.title('Top 4 feature importance ranking')
plt.xlabel('mean decrease in model accuracy')
plt.ylabel('Feature')
plt.grid(axis='x',visible=False)
plt.show()