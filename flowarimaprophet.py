# -*- coding: utf-8 -*-
"""flowARIMAprophet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IxymAcfCxk_8m1GosLhBdNGCEeZ0vNic
"""

import nbconvert
import os            ##  This module is for "operating system" interfaces
import sys           ##  This module is for functionality relevant to the python run time
import numpy as np
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
GOOGLE_DRIVE_PATH = os.path.join('drive','My Drive', '/content/drive/MyDrive/Colab Notebooks/PhD research/')

sys.path.append(GOOGLE_DRIVE_PATH)
os.chdir(GOOGLE_DRIVE_PATH)

!pip install prophet

"""#predicting future flows based on prophet model only - the residual plot shows a pattern meaning we are not capturing some underlying trends. How can we improve this?

Note: including lagged variables worsened performance. so had to drop this idea.
"""

import pandas as pd
from prophet import Prophet
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

data = pd.read_csv('plant_flow_data.csv')
data['date'] = pd.to_datetime(data['date'])
data.set_index('date', inplace=True)
prophet_data = data[['flow', 'rainfall', 'season', 'ADD']].reset_index()
prophet_data.columns = ['ds', 'y', 'rainfall', 'season', 'ADD']

label_encoder = LabelEncoder()
prophet_data['season'] = label_encoder.fit_transform(prophet_data['season']) #transform season to numerical


train_size = int(len(prophet_data) * 0.8) #split data here in a sequential way
train, test = prophet_data[:train_size], prophet_data[train_size:]

model = Prophet()
model.add_regressor('rainfall')
model.add_regressor('season')
model.add_regressor('ADD') # these are the antecendent dry days which are calculated based on the time between rainfall greater than 0.04 inches. ADD computation should be added before running the model in the final script
model.fit(train)

# here we are creating future data while at the same time setting the regressors
future = model.make_future_dataframe(periods=len(test))
future['rainfall'] = np.tile(train['rainfall'].values[-1], len(future))
future['ADD'] = np.tile(train['ADD'].values[-1], len(future))
future['season'] = np.tile(label_encoder.transform(label_encoder.inverse_transform(train['season'])),
                           int(np.ceil(len(future) / len(train))))[:len(future)]

forecast = model.predict(future)

# model performance
y_true = test['y'].values
y_pred = forecast['yhat'].values[-len(test):]

mae = mean_absolute_error(y_true, y_pred)
rmse = np.sqrt(mean_squared_error(y_true, y_pred))
r2 = 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))


# here lets plot the model results
fig = model.plot(forecast)
plt.title('flow with prophet')
plt.xlabel('time')
plt.ylabel('flow (million gallons per day)')
plt.grid(False)
plt.show()

# take a look at the residuals analysis plt. Note: there is a pattern which might mean we are missing out some of these patterns during model training. think how to fix this. how?? - Dr.Carlson can help??
residuals = y_true - y_pred
plt.figure(figsize=(10, 6))
plt.plot(test['ds'], residuals,linestyle='-', color='b')
plt.axhline(0, color='red', linestyle='--')
plt.title('Residuals')
plt.xlabel('Time')
plt.ylabel('Residuals')
plt.grid(False)
plt.show()

"""# ARIMA - here we determine if our given time series (target and predictors) are stationary - all variables for ARIMA were found to be stationary. so no need to transform them but found out p, d,q automatically"""

import pandas as pd
from statsmodels.tsa.stattools import adfuller
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
data['season'] = label_encoder.fit_transform(data['season']) # we have to make the season variable numerical

def adf_test_all(data, columns):
    for column in columns:
        result = adfuller(data[column])
        print(f'ADF Statistic for {column}: {result[0]}')
        print(f'p-value: {result[1]}')
        print('Critical Values:')
        for key, value in result[4].items():
            print(f'\t{key}: {value}')
        print()

our_data = ['flow', 'rainfall', 'season', 'ADD']

adf_test_all(data, our_data)

"""# ARIMA model only"""

import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

plt.figure(figsize=(12, 10))

# ACF for flow
plt.subplot(3, 2, 1)
plot_acf(data['flow'], lags=20, ax=plt.gca())
plt.title('ACF for Flow')

# PACF for flow
plt.subplot(3, 2, 2)
plot_pacf(data['flow'], lags=20, ax=plt.gca())
plt.title('PACF for Flow')

# ACF for rainfall
plt.subplot(3, 2, 3)
plot_acf(data['rainfall'], lags=20, ax=plt.gca())
plt.title('ACF for Rainfall')

# PACF for rainfall
plt.subplot(3, 2, 4)
plot_pacf(data['rainfall'], lags=20, ax=plt.gca())
plt.title('PACF for Rainfall')

# ACF for ADD
plt.subplot(3, 2, 5)
plot_acf(data['ADD'], lags=20, ax=plt.gca())
plt.title('ACF for ADD')

# PACF for ADD
plt.subplot(3, 2, 6)
plot_pacf(data['ADD'], lags=20, ax=plt.gca())
plt.title('PACF for ADD')

plt.tight_layout()
plt.show()

import pandas as pd
from matplotlib import pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from math import sqrt

data = data.asfreq('D') #we are looking at daily data

data['flow_lag2'] = data['flow'].shift(2) #this provided a good correlation with flow. the rainfall lagged had no correlation so wasnt considered any further. Remember to add this piece in final script.
#data['rainfall_lag1'] = data['rainfall'].shift(1) #poor correlation with flow so not considered further
data.dropna(inplace=True)

X = data[['rainfall', 'ADD', 'season', 'flow_lag2']]
y = data['flow'].values

size = int(len(y) * 0.8) #can we try different time splits? Maybe later
train, test = y[0:size], y[size:len(y)]
X_train, X_test = X[0:size], X[size:]

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['rainfall', 'ADD', 'flow_lag2']),
        ('cat', OneHotEncoder(), ['season'])
    ])

X_train_scaled = preprocessor.fit_transform(X_train)
X_test_scaled = preprocessor.transform(X_test)


p, d, q = 1, 0, 1 #here I visually inspected the PACf and ACf plots and determined the values presented. Also- autoARIMA to find the optimal parameters didn't yield good results. Maybe straightforward approach but the outcomes not so very helpful.
model = ARIMA(train, order=(p, d, q), exog=X_train_scaled)

model_fit = model.fit()

predictions = model_fit.predict(start=len(train), end=len(train) + len(test) - 1, exog=X_test_scaled) # how are we doing on the test

rmse = sqrt(mean_squared_error(test, predictions))
mae = mean_absolute_error(test, predictions)
r2 = r2_score(test, predictions)

plt.figure(figsize=(12, 6))
dates_test = data.index[size:]  # Get the corresponding dates for the test set
dates_pred = data.index[size:len(train) + len(predictions)]  # Get dates for predictions

plt.plot(dates_test, test, label='observed', color='blue')
plt.plot(dates_pred, predictions, color='red', label='model prediction')
plt.title('ARIMA')
plt.xlabel('date')
plt.ylabel('flow (million gallons per day)')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""
# Here we combine ARIMA with prophet. ARIMA residuals to fit prophet to improve forecasting accuracy. Is this something that is usually done?"""

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from math import sqrt
from prophet import Prophet
from sklearn.preprocessing import LabelEncoder
import numpy as np


p, d, q = 1, 0, 1 #go straight into ARIMA based on previous code
model = ARIMA(train, order=(p, d, q), exog=X_train_scaled)
model_fit = model.fit()

# lets get the residuals and use them for prophet
predictions_arima = model_fit.predict(start=len(train), end=len(train) + len(test) - 1, exog=X_test_scaled)
residuals = test - predictions

residuals_test = residuals[-len(test):]  # here are we are trying to capture what ARIMA failed to understand on testing.so we need to get residuals that match the test period

# we want prophet to learn patterns in the errors made by ARIMA.thus, we fit prophet on the residuals
prophet_model = Prophet()
prophet_model.fit(prophet_data)

future = prophet_model.make_future_dataframe(periods=len(test)) # we need data for predictions so we do it here.
forecast = prophet_model.predict(future)
combined_predictions = predictions_arima + forecast['yhat'].values[-len(test):]

# combined model evalaution
rmse_comb = np.sqrt(mean_squared_error(test, combined_predictions))
mae_comb = mean_absolute_error(test, combined_predictions)
r2_comb = r2_score(test, combined_predictions)

# plotting the results
plt.figure(figsize=(12, 6))
dates_test = data.index[size:]
plt.plot(dates_test, test, label='observed', color='blue')
plt.plot(dates_test, combined_predictions, label='hybrid predictions', color='red')
plt.title('Hybrid model')
plt.xlabel('Date')
plt.ylabel('flow (million gallons per day)')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.grid(False)
plt.show()